{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d31aca7",
   "metadata": {},
   "source": [
    "# Building a Custom AI Chatbot Interface using LM Studio API and Gradio\n",
    "\n",
    "In this cell, we import the necessary libraries:\n",
    "- `os`: Provides functionalities for interacting with the operating system.\n",
    "- `openai`: The client library for interacting with OpenAI API.\n",
    "- `gradio`: A Python library used to build and launch web-based applications, here used to build the chatbot interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1553e0a-e1ce-4f31-b3c0-edea7c021910",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "import gradio as gr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4059d0f",
   "metadata": {},
   "source": [
    "## Installing LM Studio and Loading Models\n",
    "\n",
    "1. **Download and Install LM Studio**: Follow the instructions provided by LM Studio to install it locally.\n",
    "2. **Download Models**: Choose and download the required language models from the LM Studio repository.\n",
    "3. **Start the LM Studio Server**: Run the LM Studio server on `http://localhost:1234` to handle API requests.\n",
    "\n",
    "Here, the OpenAI client is initialized by the base URL where the LM Studio API is running (on localhost). The `api_key` is also provided. This client will be used to make API requests for the chatbot's responses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da451e40-bb84-46bd-81d6-a8a64a78ed70",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(base_url=\"http://localhost:1234/v1\", api_key=\"lm-studio\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc15478",
   "metadata": {},
   "source": [
    "\n",
    "This cell defines two sets of options for user selection:\n",
    "1. **System Messages**: Predefined system prompts to guide the chatbot's behavior, such as \"You are a helpful assistant.\"\n",
    "2. **Models**: Available AI models for inference. Internal names (used for API requests) are mapped to user-friendly display names. For instance, `\"phi-3.1-mini-128k-instruct\"` is displayed as `\"Phi (Microsoft)\"`.\n",
    "\n",
    "These variables will be used to populate dropdown menus in the user interface.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39085a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_messages = [\n",
    "    \"You are a helpful assistant\",  # Default message\n",
    "    \"You are a friendly advisor\",\n",
    "    \"You are a knowledgeable guide\",\n",
    "    \"You are a witty companion\"\n",
    "]\n",
    "\n",
    "# Internal model names with user-friendly display names\n",
    "models = {\n",
    "    \"phi-3.1-mini-128k-instruct\": \"Phi (Microsoft)\",\n",
    "    \"granite-3.0-2b-instruct\": \"Granite (IBM)\",\n",
    "    \"gemma-2-2b-instruct\": \"Gemma (Google)\",\n",
    "    \"llama-3.2-3b-instruct\": \"LLaMA (Meta)\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8f275b",
   "metadata": {},
   "source": [
    "\n",
    "The `chat` function handles interaction with the LM Studio API. It prepares a conversation history, which includes user inputs and assistant responses. \n",
    "1. If no chat history exists, it initializes an empty history list.\n",
    "2. The selected model's user-friendly display name is mapped back to its internal name for the API call.\n",
    "3. It prepares the system message as the initial message in the conversation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e7c5ed0-9352-4f9c-b015-5be550272fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting internal model names and their corresponding display names\n",
    "internal_models = list(models.keys())  # Internal names for API\n",
    "display_models = list(models.values())  # Display names for the dropdown\n",
    "\n",
    "def chat(message, selected_model_display, selected_system_message, history=None):\n",
    "    # Initialize history if None\n",
    "    if history is None:\n",
    "        history = []\n",
    "\n",
    "    # Map the display name back to the internal model name\n",
    "    selected_model = [k for k, v in models.items() if v == selected_model_display][0]\n",
    "\n",
    "    # Prepare the messages for the API call\n",
    "    messages = [{\"role\": \"system\", \"content\": selected_system_message}]  # Use selected system message\n",
    "    \n",
    "    # Append all history messages in the correct format\n",
    "    for user_message, assistant_message in history:\n",
    "        messages.append({\"role\": \"user\", \"content\": user_message})\n",
    "        messages.append({\"role\": \"assistant\", \"content\": assistant_message})\n",
    "\n",
    "    # Append the current user message\n",
    "    messages.append({\"role\": \"user\", \"content\": message})\n",
    "\n",
    "    # Create a chat completion request\n",
    "    try:\n",
    "        response = client.chat.completions.create(model=selected_model, messages=messages)\n",
    "        assistant_response = response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return \"Sorry, I encountered an error. Please try again.\", history\n",
    "\n",
    "    # Update history with the new message and response\n",
    "    history.append((message, assistant_response))  # Ensure history is updated correctly\n",
    "    \n",
    "    return history, history  # Return updated history for the chatbot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74cf4bf",
   "metadata": {},
   "source": [
    "\n",
    "This cell sets up the user interface for the chatbot using Gradio:\n",
    "- A header and introductory text are displayed using `Markdown`.\n",
    "- Dropdowns allow users to select the model and system prompt.\n",
    "- A chatbot component displays the conversation history.\n",
    "- A textbox is provided for user input, and buttons are provided for clearing the chat.\n",
    "- The interface listens for user input and processes chat completions by invoking the `chat` function when the user submits a message.\n",
    "- The interface is hosted on `localhost` at port `7899`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecb8130b-ac2c-4b32-b3a4-b8673bb8b250",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\iei1\\.conda\\envs\\llms\\Lib\\site-packages\\gradio\\components\\chatbot.py:222: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://0.0.0.0:7899\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://localhost:7899/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clear_chat():\n",
    "    \"\"\"Clear the chat history.\"\"\"\n",
    "    return [], []  # Return empty history and state\n",
    "\n",
    "# Set up the Gradio interface\n",
    "with gr.Blocks() as iface:\n",
    "    gr.Markdown(\"<h1 style='text-align: center;'>Chatbot Interface</h1>\")\n",
    "    gr.Markdown(\"<p style='text-align: center;'>Choose a model and start chatting with the assistant!</p>\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        model_selection = gr.Dropdown(\n",
    "            choices=display_models,  # Use the display names for the dropdown\n",
    "            label=\"Select Model\",\n",
    "            value=display_models[0],  # Default selection\n",
    "            interactive=True\n",
    "        )\n",
    "        \n",
    "        system_message_selection = gr.Dropdown(\n",
    "            choices=system_messages,  # System messages dropdown\n",
    "            label=\"Select System Message\",\n",
    "            value=system_messages[0],  # Default selection\n",
    "            interactive=True\n",
    "        )\n",
    "\n",
    "        clear_button = gr.Button(\"Clear\")  # Button to clear the chat\n",
    "\n",
    "    chatbot = gr.Chatbot()  # Chatbot for displaying history\n",
    "    user_input = gr.Textbox(placeholder=\"Type your message here...\", label=\"Your Message\")  # Textbox for user input\n",
    "    state = gr.State([])  # Maintain chat history as state\n",
    "\n",
    "    # Define the function that gets triggered on user message submission\n",
    "    user_input.submit(chat, inputs=[user_input, model_selection, system_message_selection, state], outputs=[chatbot, state])\n",
    "    user_input.submit(lambda: \"\", outputs=user_input)  # Clear the input box after submission\n",
    "    clear_button.click(clear_chat, outputs=[chatbot, state])  # Connect the clear button to clear_chat function\n",
    "\n",
    "iface.launch(server_name=\"0.0.0.0\", server_port=7899)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c348ba-d107-47f0-80a9-af8605fbef5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
